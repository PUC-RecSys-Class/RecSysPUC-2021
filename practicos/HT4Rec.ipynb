{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HT4Rec.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
	{
	"cell_type": "markdown",
	"metadata": {
	"colab_type": "text",
	"id": "view-in-github"
	},
	"source": [
	"<a href=\"https://colab.research.google.com/github/PUC-RecSys-Class/RecSysPUC-2021/blob/master/practicos/HT4Rec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
	]
	},
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZujf16p_c2y"
      },
      "source": [
        "# H-Transformer for Item Recommendation in MOBA Games\n",
        "\n",
        "Vladimir Araujo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybR1dWGRAIda"
      },
      "source": [
        "## Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKIBwjERa-dT"
      },
      "source": [
        "!pip install python-box\n",
        "!wget https://gist.githubusercontent.com/vgaraujov/47ef44430fdbcc95dcb6c87233c3ef92/raw/97c4608ee2b62c77929784e0d07e05ff27b56ee4/drive_download.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FBcRa_eWsTO"
      },
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzgP0fnAa-3f"
      },
      "source": [
        "import drive_download\n",
        "\n",
        "idx = '19oln5xzNGI50KwO7kIP3HADQOeIXMW-R'\n",
        "drive_download.drive_download(drive, idx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eboJpTf7fSN3"
      },
      "source": [
        "!mv drive_download/* ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTPvgHwFQJs_"
      },
      "source": [
        "import time\n",
        "import os\n",
        "import logging\n",
        "import yaml\n",
        "from timeit import default_timer as timer\n",
        "\n",
        "## Libraries\n",
        "import numpy as np\n",
        "from box import box_from_file\n",
        "from pathlib import Path\n",
        "\n",
        "## Torch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils import data\n",
        "import torch.optim as optim\n",
        "\n",
        "## Custom Imports\n",
        "from logger import setup_logs\n",
        "from seed import set_seed\n",
        "from train import train, snapshot\n",
        "from validation import validation\n",
        "from dataset import DotaDataset, DataCollatorForDota\n",
        "from model_aux import HTransformer\n",
        "import losses"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGJmV8y0BwdZ"
      },
      "source": [
        "## Training Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1OG_Wy_d7Fr"
      },
      "source": [
        "############ Control Center and Hyperparameter ###############\n",
        "config = box_from_file(Path('config.yaml'), file_type='yaml')\n",
        "config.training.logging_dir = '.'\n",
        "config.dataset.train_data_path = '/content/training_all.pkl'\n",
        "config.dataset.test_data_path = '/content/testing_all.pkl'\n",
        "config.dataset.item_path = '/content/item_ids.csv'\n",
        "config.dataset.champ_path = '/content/hero_names.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ze3ArW1k5xW"
      },
      "source": [
        "run_name = config.model.model_type + time.strftime(\"-%Y-%m-%d_%H_%M_%S\")\n",
        "# setup logger    \n",
        "global_timer = timer() # global timer\n",
        "logger = setup_logs(config.training.logging_dir, run_name) # setup logs\n",
        "logger.info('### Experiment {} ###'.format(run_name))\n",
        "logger.info('### Hyperparameter summary below ###\\n {}'.format(config))\n",
        "    \n",
        "# define if gpu or cpu\n",
        "use_cuda = not config.training.no_cuda and torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "logger.info('===> use_cuda is {}'.format(use_cuda))\n",
        "# set seed for reproducibility\n",
        "set_seed(config.training.seed, use_cuda)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5_MPUo3k6m3"
      },
      "source": [
        "## Loading the dataset\n",
        "logger.info('===> loading train and validation dataset')\n",
        "train_dataset = DotaDataset(config, 'train')\n",
        "validation_dataset = DotaDataset(config, 'test')\n",
        "\n",
        "data_collator = DataCollatorForDota(max_length = config.dataset.max_seq_length)\n",
        "\n",
        "multiplier = torch.cuda.device_count() if not config.training.no_cuda else 1\n",
        "batch_size = int(config.training.batch_size*multiplier)\n",
        "train_loader = data.DataLoader(train_dataset,\n",
        "                               batch_size=batch_size,\n",
        "                               collate_fn=data_collator,\n",
        "                               drop_last=True\n",
        "                              )\n",
        "validation_loader = data.DataLoader(validation_dataset, \n",
        "                                    batch_size=batch_size, # batch 1 for evaluate variable length\n",
        "                                    collate_fn=data_collator,\n",
        "                                    drop_last=True\n",
        "                                   )\n",
        "\n",
        "config.dataset.n_items = len(train_dataset.id2item)\n",
        "config.dataset.n_champs = len(train_dataset.id2champ)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K06uuWT-mbAK"
      },
      "source": [
        "model = HTransformer(config=config)\n",
        "# move to device\n",
        "model.to(device)\n",
        "\n",
        "# Adam optimizer\n",
        "optimizer = optim.Adam(\n",
        "        filter(lambda p: p.requires_grad, model.parameters()), \n",
        "        lr=2e-4, betas=(0.9, 0.98), eps=1e-09, weight_decay=1e-4, amsgrad=True)\n",
        "if config.training.resume_name:\n",
        "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "\n",
        "# create loss function\n",
        "loss_fn = losses.LossFunction(loss_type=config.model.loss_fn)\n",
        "    \n",
        "model_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "logger.info('### Model summary below ###\\n {}'.format(str(model)))\n",
        "logger.info('===> Model total parameter: {}\\n'.format(model_params))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-RLv8sdmmbo"
      },
      "source": [
        "best_acc = 0\n",
        "best_loss = np.inf\n",
        "best_epoch = -1 \n",
        "step = 0\n",
        "initial_epoch = 1\n",
        "    \n",
        "logger.info('### Training begins at epoch {} and step {} ###'.format(initial_epoch,step))\n",
        "for epoch in range(initial_epoch, config.training.epochs + 1):\n",
        "    epoch_timer = timer()\n",
        "    # Train and validate\n",
        "    tr_acc, tr_loss, step = train(\n",
        "        step, \n",
        "        model, \n",
        "        train_loader, \n",
        "        loss_fn, \n",
        "        device, \n",
        "        optimizer, \n",
        "        epoch, \n",
        "        config.training.log_interval)\n",
        "    \n",
        "    if not epoch % 10:    \n",
        "        val_acc, val_loss = validation(\n",
        "            step, \n",
        "            model, \n",
        "            validation_loader, \n",
        "            loss_fn, \n",
        "            device)\n",
        "        # Save\n",
        "        if val_loss < best_loss: \n",
        "            best_loss = min(val_loss, best_loss)\n",
        "            if torch.cuda.device_count() > 1 and not config.training.no_cuda:\n",
        "                dict_to_save = model.module.state_dict()\n",
        "            else:\n",
        "                dict_to_save = model.state_dict()\n",
        "            snapshot(config.training.logging_dir, run_name, {\n",
        "                'epoch': epoch,\n",
        "                'step_train': step,\n",
        "                'validation_acc': val_acc,\n",
        "                'validation_loss': val_loss,\n",
        "                'state_dict': dict_to_save,\n",
        "                'optimizer': optimizer.state_dict(),\n",
        "            })\n",
        "            best_epoch = epoch\n",
        "\n",
        "    end_epoch_timer = timer()\n",
        "    logger.info(\"#### End epoch {}/{}, elapsed time: {}\".format(epoch, config.training.epochs, end_epoch_timer - epoch_timer))\n",
        "    \n",
        "## end \n",
        "end_global_timer = timer()\n",
        "logger.info(\"################## Success #########################\")\n",
        "logger.info(\"Total elapsed time: %s\" % (end_global_timer - global_timer))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6vF5SRAEXGN"
      },
      "source": [
        "## Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7njMbj5v_8Nd"
      },
      "source": [
        "import numpy as np; np.random.seed(0)\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUlTVc5SB2EW"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "def open_champs_info(champs_path):\n",
        "    champs_df = pd.read_csv(champs_path)\n",
        "    champs_df.drop([106, 111], inplace = True)\n",
        "    champs_df.drop(['name'], axis = 1, inplace = True)\n",
        "    champs_df.reset_index(drop=True, inplace=True)\n",
        "    names = champs_df['localized_name'].tolist()\n",
        "    dictionary = {names[i] : v for i, v in enumerate(champs_df['hero_id'].tolist())}\n",
        "    dictionary[0] = 0\n",
        "    reversed_dictionary = {value : key for (key, value) in dictionary.items()}\n",
        "    return dictionary, reversed_dictionary\n",
        "\n",
        "_, mapping = open_champs_info(config.dataset.champ_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9-h5i5eO4op"
      },
      "source": [
        "run_name = 'HTransformerV3-2021-10-30_04_30_23'\n",
        "logger.info('===> loading a checkpoint')\n",
        "checkpoint = torch.load('{}/{}-{}'.format(config.training.logging_dir, run_name, 'model_best.pth'))\n",
        "model.load_state_dict(checkpoint['state_dict'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4sW9jNz_qVy"
      },
      "source": [
        "validation_loader = data.DataLoader(validation_dataset, \n",
        "                                    batch_size=1, # batch 1 for evaluate variable length\n",
        "                                    collate_fn=data_collator,\n",
        "                                    drop_last=True,\n",
        "                                    shuffle=True\n",
        "                                   )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4nRAiVn_6q5"
      },
      "source": [
        "champs, items, target, attn_mask = next(iter(validation_loader))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKaI0GLdAKR8"
      },
      "source": [
        "output, attn_1, attn_2 = model(champs.cuda(), items.cuda())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNesJdO-AYVT"
      },
      "source": [
        "data_1=attn_1.detach().cpu().numpy()\n",
        "data_2=attn_2.squeeze(0).detach().cpu().numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Meu8ytkJB48Q"
      },
      "source": [
        "heros = champs.detach().cpu().squeeze(0).tolist()\n",
        "name_heros = []\n",
        "for i in heros:\n",
        "    name_heros.append(mapping[int(i)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Oq4kOllC1U1"
      },
      "source": [
        "fig,axn = plt.subplots(5, 1, sharex=True, sharey=True, figsize=(10,6))\n",
        "\n",
        "aux = 2\n",
        "for i, ax in enumerate(axn.flat):\n",
        "    df = pd.DataFrame(data_1[i+aux], index=name_heros, columns=name_heros)\n",
        "    df.drop(labels=name_heros[1:], axis=0, inplace=True)\n",
        "#     ax.set_title(\"Step \"+str(i+aux))\n",
        "    sns.heatmap(df, ax=ax, cmap=\"Blues\", cbar=True)\n",
        "plt.xlabel(\"Heros\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-9UU6SzAnbV"
      },
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "ax = sns.heatmap(data_2, cmap=\"Blues\")\n",
        "plt.xlabel(\"Sequence Step\")\n",
        "plt.ylabel(\"Sequence Step\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}